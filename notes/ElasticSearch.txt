ElasticSearch



//ES命令行
D:\Program Files\elasticsearch-2.0.0>

//把Elasticsearch安装为系统服务(bin 目录下：)
service.bat install 

//启动服务
service.bat start
service.bat stop





Exception in thread "main" java.lang.RuntimeException: don't run elasticsearch as root.
=======>>
//创建elsearch用户组及elsearch用户
> groupadd elsearch
> useradd elsearch -g elsearch -p elasticsearch

//更改elasticsearch文件夹及内部文件的所属用户及组为elsearch:elsearch
> cd /opt
> chown -R elsearch:elsearch  elasticsearch-2.1.0   
 chown -R userName:groupName 文件名/文件路径 ；把目录授权给用户

//切换到elsearch用户再启动
> su - elsearch    //切换到用户 elsearch
> ./elasticsearch 






linux 安装ElasticSearch-2.1.0
参考：https://www.elastic.co/guide/en/elasticsearch/reference/current/_installation.html

步骤如下：
1、> curl -L -O https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.1.0/elasticsearch-2.1.0.tar.gz
2、> tar -xvf elasticsearch-2.1.0.tar.gz
3、>cd elasticsearch-2.1.0/bin
4、>./elasticsearch







Index --  Type  -- Document  -- field
	
GET /_search	--在所有索引的所有类型中搜索
GET /_search?timeout=10ms   --Elasticsearch将返回在请求超时前收集到的结果
====>
{
   "took": 9,		--整个搜索请求花费的毫秒数
   "timed_out": false,	--查询超时与否，一般的，搜索请求不会超时。如果响应速度比完整的结果更重要，你可以定义timeout参数为10或者10ms（10毫秒），或者1s（1秒）
   "_shards": {
      "total": 15,		--参与查询的分片数
      "successful": 15,	--有多少是成功的
      "failed": 0		--有多少的是失败的
   },
   "hits": {
      "total": 16,   	--匹配到的文档总数
      "max_score": 1,   --指的是所有文档匹配查询中_score的最大值
      "hits": [			--数组还包含了匹配到的前10条数据
         {
            "_index": "us",
            "_type": "tweet",
            "_id": "14",
            "_score": 1,	--相关性得分,衡量文档与查询的匹配程度；默认按照_score降序排列。
            "_source": {
               "date": "2014-09-24",
               "name": "John Smith",
               "tweet": "How many more cheesy tweets do I have to write?",
               "user_id": 1
            }
         },
		 ……
	 }
}

/_search
在所有索引的所有类型中搜索

/gb/_search
在索引gb的所有类型中搜索

/gb,us/_search
在索引gb和us的所有类型中搜索

/g*,u*/_search
在以g或u开头的索引的所有类型中搜索

/gb/user/_search
在索引gb的类型user中搜索

/gb,us/user,tweet/_search
在索引gb和us的类型为user和tweet中搜索

/_all/user,tweet/_search
在所有索引的user和tweet中搜索 search types user and tweet in all indices



结构化查询 Query DSL

查询子句:一个查询子句一般使用这种结构：
{
    QUERY_NAME: {
        ARGUMENT: VALUE,
        ARGUMENT: VALUE,...
    }
}
或指向一个指定的字段：
{
    QUERY_NAME: {
        FIELD_NAME: {
            ARGUMENT: VALUE,
            ARGUMENT: VALUE,...
        }
    }
}
eg.
{
    "match": {
        "tweet": "elasticsearch"
    }
}
完整的查询请求会是这样：
GET /_search
{
    "query": {
        "match": {
            "tweet": "elasticsearch"
        }
    }
}



最重要的查询过滤语句 [filter ]

term 过滤
	term主要用于精确匹配哪些值，比如数字，日期，布尔值或 not_analyzed的字符串(未经分析的文本数据类型)：
terms 过滤	
	terms 跟 term 有点类似，但 terms 允许指定多个匹配条件。 如果某个字段指定了多个值，那么文档需要一起去做匹配
range 过滤
	range过滤允许我们按照指定范围查找一批数据：
	{
    "range": {
        "age": {
            "gte":  20,
            "lt":   30
			}
		}
	}
	范围操作符包含：
		gt :: 大于
		gte:: 大于等于
		lt :: 小于
		lte:: 小于等于
exists 和 missing 过滤
	exists 和 missing 过滤可以用于查找文档中是否包含指定字段或没有某个字段，类似于SQL语句中的IS_NULL条件
	{
    "exists":   {
        "field":    "title"
		}
	}
bool 过滤
	bool 过滤可以用来合并多个过滤条件查询结果的布尔逻辑，它包含一下操作符：
		must :: 多个查询条件的完全匹配,相当于 and。
		must_not :: 多个查询条件的相反匹配，相当于 not。
		should :: 至少有一个查询条件匹配, 相当于 or。

		
		
		
[query ]

match_all 查询
	使用match_all 可以查询到所有文档，是没有查询条件下的默认语句
match 查询
	match查询是一个标准查询，不管你需要全文本查询还是精确查询基本上都要用到它。
multi_match 查询	
	multi_match查询允许你做match查询的基础上同时搜索多个字段：
bool 查询
	bool 查询与 bool 过滤相似，用于合并多个查询子句。不同的是，bool 过滤可以直接给出是否匹配成功， 而bool 查询要计算每一个查询子句的 _score （相关性分值）。
		must:: 查询指定文档一定要被包含。
		must_not:: 查询指定文档一定不要被包含。
		should:: 查询指定文档，有则可以为文档相关性加分。
		

查询与过滤条件的合并	
		
复合查询语句可以加入其他查询子句，复合过滤语句也可以加入其他过滤子句。 通常情况下，一条查询语句需要过滤语句的辅助，全文本搜索除外。

search API中只能包含 query 语句，所以我们需要用 filtered 来同时包含 "query" 和 "filter" 子句：
{
    "filtered": {
        "query":  { "match": { "email": "business opportunity" }},
        "filter": { "term":  { "folder": "inbox" }}
    }
}




===========>>=========================================================================================

映射(mapping)机制用于进行字段类型确认，将每个字段匹配为一种确定的数据类型(string, number, booleans, date等)。

分析(analysis)机制用于进行全文文本(Full Text)的分词，以建立供搜索用的反向索引。

Elasticsearch中的数据可以大致分为两种类型：确切值 及 全文文本

==>> 确切值(Exact values) vs. 全文文本(Full text)
	确切值是很容易查询的，因为结果是二进制的 -- 要么匹配，要么不匹配
	而对于全文数据的查询来说，却有些微妙。我们不会去询问这篇文档是否匹配查询要求？ 但是，我们会询问这篇文档和查询的匹配程度如何？。换句话说，对于查询条件，这篇文档的相关性有多高？
	
	为了方便在全文文本字段中进行这些类型的查询，Elasticsearch首先对文本分析(analyzes)，然后使用结果建立一个倒排索引。我们将在以下两个章节讨论倒排索引及分析过程。
	
	Elasticsearch使用一种叫做倒排索引(inverted index)的结构来做快速的全文搜索。倒排索引由在文档中出现的唯一的单词列表，以及对于每个单词在文档中的位置组成。

分词(analysis) ===>> 分析和分析器

	分析(analysis)是这样一个过程：
	>>首先，表征化一个文本块为适用于倒排索引单独的词(term)
	>>然后标准化这些词为标准形式，提高它们的“可搜索性”或“查全率”
	这个工作是分析器(analyzer)完成的。

一个分析器(analyzer)只是一个包装用于将三个功能放到一个包里：
	>字符过滤器  == 字符过滤器(character filter)，在表征化（断词）前处理字符串,字符过滤器能够去除或者转换HTML标记。
	>分词器  == 分词器(tokenizer)，被表征化（断词）为独立的词。
	>表征过滤  == 表征过滤(token filters)，它可以修改词（如转为小写），去掉词（如停用词a、and、the），或者增加词（如同义词）

内建的分析器
	Elasticsearch还附带了一些预装的分析器，你可以直接使用它们。
	
	*标准分析器
	标准分析器是Elasticsearch默认使用的分析器。
	它根据Unicode Consortium的定义的单词边界(word boundaries)来切分文本，然后去掉大部分标点符号。最后，把所有词转为小写。

	*简单分析器
	简单分析器将非单个字母的文本切分，然后把每个词转为小写。
	
	*空格分析器
	空格分析器依据空格切分文本。它不转换小写。
	
	*语言分析器
	特定语言分析器适用于很多语言。它们能够考虑到特定语言的特性。

当分析器被使用
	当我们索引(index)一个文档，全文字段会被分析为单独的词来创建倒排索引。
	不过，当我们在全文字段搜索(search)时，我们要让查询字符串经过同样的分析流程处理，以确保这些词在索引中存在。

	当你查询全文(full text)字段，查询将使用相同的分析器来分析查询字符串，以产生正确的词列表。
	当你查询一个确切值(exact value)字段，查询将不分析查询字符串，但是你可以自己指定。
	例如：
	date字段包含一个确切值：单独的一个词"2014-09-15"。
	_all字段是一个全文字段，所以分析过程将日期转为三个词："2014"、"09"和"15"。


===========>>==============================

映射

>索引中每个文档都有一个类型(type)。 每个类型拥有自己的映射(mapping)或者模式定义(schema definition)。
>一个映射定义了字段类型，每个字段的数据类型，以及字段被Elasticsearch处理的方式。映射还用于设置关联到类型上的元数据。

更新映射
>你可以在第一次创建索引的时候指定映射的类型。此外，你也可以晚些时候为新类型添加映射（或者为已有的类型更新映射）。

重要
>你可以向已有映射中增加字段，但你不能修改它。如果一个字段在映射中已经存在，这可能意味着那个字段的数据已经被索引。如果你改变了字段映射，那已经被索引的数据将错误并且不能被正确的搜索到。

//删除索引gb
DELETE /gb
//创建一个新索引，指定tweet字段的分析器为english：
PUT /gb 
{
  "mappings": {
    "tweet" : {
      "properties" : {
        "tweet" : {
          "type" :    "string",
          "analyzer": "english"
        },
        "date" : {
          "type" :   "date"
        },
        "name" : {
          "type" :   "string"
        },
        "user_id" : {
          "type" :   "long"
        }
      }
    }
  }
}

//映射中增加一个新的not_analyzed类型的文本字段，叫做tag，使用_mapping后缀:
PUT /gb/_mapping/tweet
{
  "properties" : {
    "tag" : {
      "type" :    "string",
      "index":    "not_analyzed"
    }
  }
}


自定义动态索引

如果你想在运行时的增加新的字段，你可能会开启动态索引。虽然有时动态映射的 规则 显得不那么智能，幸运的是我们可以通过设置来自定义这些规则。




动态模板

使用 dynamic_templates，你可以完全控制新字段的映射，你设置可以通过字段名或数据类型应用一个完全不同的映射。

每个模板都有一个名字用于描述这个模板的用途，一个 mapping 字段用于指明这个映射怎么使用，和至少一个参数（例如 match）来定义这个模板适用于哪个字段。


批量重新索引：

	虽然你可以给索引添加新的类型，或给类型添加新的字段，但是你不能添加新的分析器或修改已有字段。假如你这样做，已被索引的数据会变得不正确而你的搜索也不会正常工作。

	修改在已存在的数据最简单的方法是重新索引：创建一个新配置好的索引，然后将所有的文档从旧的索引复制到新的上。

	你可以在同一时间执行多个重新索引的任务，但是你显然不愿意它们的结果有重叠。所以，可以将重建大索引的任务通过日期或时间戳字段拆分成较小的任务：
	GET /old_index/_search?search_type=scan&scroll=1m
	{
		"query": {
			"range": {
				"date": {
					"gte":  "2014-01-01",
					"lt":   "2014-02-01"
				}
			}
		},
		"size":  1000
	}

	
	
	
索引 别名
 就像一个快捷方式或软连接，可以指向一个或多个索引，也可以给任何需要索引名的 API 使用。别名带给我们极大的灵活性，允许我们做到：
	在一个运行的集群上无缝的从一个索引切换到另一个
	给多个索引分类（例如，last_three_months）
	给索引的一个子集创建 视图
所以请做好准备：在应用中使用别名而不是索引。然后你就可以在任何时候重建索引。别名的开销很小，应当广泛使用。



IK 分词安装：

> git clone https://github.com/medcl/elasticsearch-analysis-ik 
> cd /git/~~/elasticsearch-analysis-ik 
> mvn clean package 
> copy & unzip file #{project_path}/elasticsearch-analysis-ik/target/releases/elasticsearch-analysis-ik-*.zip to your elasticsearch's folder: plugins/ik
> copy /git/~~/elasticsearch-analysis-ik/config/ik to esfolder/config/ik 
> restart elasticsearch

mvn : apache 打包工具，单独安装，同jdk ，
> mvn -v  安装成功测试


